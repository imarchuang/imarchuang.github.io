
# 用户行为数据的收集和报表

### 先BB
> 这个系统设计题，似乎是个`Senior`的入门级的考题，我在`Facebook`和`Amazon`的面试里都被面到了。
> Facebook的题更直接点：假设你有一个1000万个广告商，然后你可以在1亿个网站/网址上打广告，现在让你设计一个广告平台可以实时的(real-time)收集打出去的广告的统计数据。题里还有给出一个条件，那就是你只需要收集两种信息，那就是打出去的广告会有两种action，一种叫impression(就是说用户至少看到了广告但是啥都没做)，另一种叫click(那就是说用户看到了广告而且点了那个广告)。
> Amazon的题虽然不明显，但是更简单点儿：假设你有一个1000万个网址，现在让你设计一个系统可以实时的(real-time)收集这些网址的访问量。
>
>这两题的核心component都是一个能实时数据处理的系统，如果说的更直接一点，那就是让你设计一个mini版的Storm或者Kafka，为了计算需要实时计算的数据可以控制在一定的size里，你肯定需要设计一些offline的job来做batch预处理，好吧一些历史数据的统计结果先算出来存好。
>

### 言归正传 -- 面试技巧
>?**重点** 这里Scenario部分的时候，算出DAU啊，Traffic之类的并不是重点，因为这些其实就是数学计算而已，Scenario里重中之重是clarify所需要的functional requirements，说白话就是需要展示给广告商的报表有哪几种。这里如果你不幸的碰到的是印度小哥，他很可能误导你说这个需要非常flexible，用户想要什么他们就应该得到什么。你不用管面试官说啥，你要告诉他这个->**你想展现的报表有两大类，一类是预设好的，比如说总的impression，总的click，每个小时的impression和click的累计，每个小时每个网址的impression和click的累计等等；第二类是可以让用户self serve的，他们可以创建任意的组合进行数据分析**，分这两类的重点就是第一类会有实时的报表，第二类呢则需要时间才能得到答案。

>?**重点** 这里在你说你的细节Deisgn时候，有一点一定要提到，那就是所谓的**sampling**的概念，就是你的subscribe那个streaming queue的服务(计算各种统计数据用的)，不一定要每增加一个event就需要更新终点的的cache，因为这样对网络吞吐量要求很高，终端用户也不需要如此精确的统计数据，这里的**sampling**策略有两个，一是每增加1000个event再往下游推送，二是1分钟了还没增加到1000个那也往下游推送，实际生产环境中都是这两种策略的结合。
